<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <title></title>
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href="../cs180.css">
        <link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
        
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            }
        };
    </script>
    <script id="MathJax-script" async=async
            src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>
    </head>

    <body>

        <h1 align="middle">Neural Radiance Fields</h1>
        <h2 align="middle">CS 180: Computer Vision and Computational Photography, Fall 2024</h1>
        <h2 align="middle">Rebecca Feng and Austin Zhu</h2>
        <div align="middle">
            <img src="images/part2/nerf.gif" alt="" width="300px">

        </div>
        <p>
            <a href="../hdr/hdr.html">Link to second project </a>
        </p>
        <p>
            
            We can reconstruct a scene in 3D given only a series of images that capture the scene, along with each image's associated
            camera extrinsics and intrinsics. One method of scene reconstruction is through neural radiance fields (<a href="https://www.matthewtancik.com/nerf">paper here</a>),
            which, given an arbitrary camera position and rotation, can reconstruct an image view by calculating each pixel's color and density. For scene
            reconstruction, we first break down each training image into varying frequency levels via positional encoding, then train a model to generalize this 
            to predict the corresponding colors and densities at any arbitrary camera position and rotation.
        </p>
        <br>

        <!-- Beginning of Part A -->

        <h2 align="middle">
            Part A:  Fit a Neural Field to a 2D Image
        </h2>
        
        <div align="middle" class="mathjax">
            <div align="middle">
                <p>
                   To motivate the idea of using positional encoding to reconstruct images in 3D, we first look at a simpler 2D case and create a "neural field". We attempt to reconstruct
                   images with positional encoding, which predicts RGB values based on 2D image coordinates $x = (u,v)$. We use $L$ to denote the maximum frequency
                   we compute the positional encoding of $x$ for.
                   The equation to break a coordinate $x$ down to 
                   its higher-dimensional positional encoding representation is given by:
                </p>
                \[
                PE(x) = \{x, sin(2^0\pi x), cos(2^0\pi x),
                    sin(2^1\pi x), cos(2^1\pi x), ..., sin(2^{L-1}\pi x), cos(2^{L-1}\pi x)\}
                \]
                <p>
                    Afterwards, we can train an image to predict the rgb color of an image given its image coordinate $x$ using the following multi-layer perception
                    network:
                </p>
                <img src="images/part1/mlp_img.jpg" alt="" width="500px">
                <p>
                    Here are several results of image reconstruction. To start, we train with the following parameters: MSE loss, Adam optimizer 0.01 learning rate, 
                    10000 batch size of pixel coordinates, 3000 iterations, 256 hidden layers, 10 positional encoding levels. Then, we compare the quality of our result
                     by modifying the number of positional encoding levels to 5, and the number of hidden layers to 64, separately. We notice that higher levels of 
                     positional encoding levels and hidden layers result in higher quality.
                </p>
            </div>
            <div align="middle">
                
                <h4>
                    Original image
                </h4>
                <img src="images/part1/fox/15677707699_d9d67acf9d_b.jpg" alt="" width="500px">
                <figcaption>
                    A fox!
                </figcaption>

                <br>
                <h4>
                    Baseline: 3000 Iterations, 10 Positional Encoding Levels, 256 Hidden Layers, 0.01 Learning Rate
                </h4>
                <div>
                    <table>
                        <tr>
                            <td>
                                <img src="images/part1/fox/3000i_L10_h256_lr001/psnr1.png" alt="" width="300px">
                            </td>
                            <td>
                                <img src="images/part1/fox/3000i_L10_h256_lr001/images1/fox_240.jpeg" alt=""  width="300px">
                            </td>
                            <td>
                                <img src="images/part1/fox/3000i_L10_h256_lr001/fox1.mov" alt=""  width="300px">
                            </td>
                            
                        </tr>
                        <td>
                            <figcaption>
                                PSNR levels over 3000 iterations
                            </figcaption>
                        </td>
                        <td>
                            <figcaption>
                                Final reconstructed image
                            </figcaption>
                        </td>
                        <td>
                            <figcaption>
                                Image reconstruction while training
                            </figcaption>
                        </td>
                        
                    </table>
                    <br>
                    <table>
                        <tr>
                            <td>
                                <img src="images/part1/fox/3000i_L10_h256_lr001/images1/fox_1.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fox/3000i_L10_h256_lr001/images1/fox_60.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fox/3000i_L10_h256_lr001/images1/fox_120.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fox/3000i_L10_h256_lr001/images1/fox_180.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fox/3000i_L10_h256_lr001/images1/fox_300.jpeg" alt=""  width="200px">
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <figcaption>
                                    i=0
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=600
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=1200
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=1800
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=3000
                                </figcaption>
                            </td>
                        </tr>
                    </table>
                </div>
                <br>

                <h4>
                    Vary Positional Encoding: 3000 Iterations, <i>5 Positional Encoding Levels</i> , 256 Hidden Layers, 0.01 Learning Rate
                </h4>
                <div>
                    <table>
                        <tr>
                            <td>
                                <img src="images/part1/fox/3000i_L5_h256_lr001/psnr3.png" alt="" width="300px">
                            </td>
                            <td>
                                <img src="images/part1/fox/3000i_L5_h256_lr001/images3/fox_150.jpeg" alt=""  width="300px">
                            </td>
                            <td>
                                <img src="images/part1/fox/3000i_L5_h256_lr001/fox3.mov" alt=""  width="300px">
                            </td>
                        
                        </tr>
                        <td>
                            <figcaption>
                                PSNR levels over 3000 iterations
                            </figcaption>
                        </td>
                        <td>
                            <figcaption>
                                Final reconstructed image
                            </figcaption>
                        </td>
                        <td>
                            <figcaption>
                                Image reconstruction while training
                            </figcaption>
                        </td>
                    </table>
                    <br>
                    <table>
                        <tr>
                            <td>
                                <img src="images/part1/fox/3000i_L5_h256_lr001/images3/fox_1.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fox/3000i_L5_h256_lr001/images3/fox_30.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fox/3000i_L5_h256_lr001/images3/fox_60.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fox/3000i_L5_h256_lr001/images3/fox_90.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fox/3000i_L5_h256_lr001/images3/fox_150.jpeg" alt=""  width="200px">
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <figcaption>
                                    i=0
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=600
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=1200
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=1800
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=3000
                                </figcaption>
                            </td>
                        </tr>
                    </table>
                </div>
                <br>
                <h4>
                    Vary Hidden Layers: 3000 Iterations, 10 Positional Encoding Levels, <i>64 Hidden Layers</i>, 0.01 Learning Rate
                </h4>
                <div>
                    <table>
                        <tr>
                            <td>
                                <img src="images/part1/fox/3000i_L10_h64_lr001/psnr2.png" alt="" width="300px">
                            </td>
                            <td>
                                <img src="images/part1/fox/3000i_L10_h64_lr001/images2/fox_150.jpeg" alt=""  width="300px">
                            </td>
                            <td>
                                <img src="images/part1/fox/3000i_L10_h64_lr001/fox2.mov" alt=""  width="300px">
                            </td>
                            
                        </tr>
                        <td>
                            <figcaption>
                                PSNR levels over 3000 iterations
                            </figcaption>
                        </td>
                        <td>
                            <figcaption>
                                Final reconstructed image
                            </figcaption>
                        </td>
                        <td>
                            <figcaption>
                                Image reconstruction while training
                            </figcaption>
                        </td>
                        
                    </table>
                    <br>
                    <table>
                        <tr>
                            <td>
                                <img src="images/part1/fox/3000i_L10_h64_lr001/images2/fox_1.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fox/3000i_L10_h64_lr001/images2/fox_30.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fox/3000i_L10_h64_lr001/images2/fox_60.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fox/3000i_L10_h64_lr001/images2/fox_90.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fox/3000i_L10_h64_lr001/images2/fox_150.jpeg" alt=""  width="200px">
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <figcaption>
                                    i=0
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=600
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=1200
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=1800
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=3000
                                </figcaption>
                            </td>
                        </tr>
                    </table>
                </div>
            </div>
            <div align="middle">
                <br>
                <h4>
                    Own image
                </h4>
                <p>
                    Here, we vary the positional encoding levels from 1 to 5 to 10 and compare the quality of the final reconstructed image.
                    As expected, higher levels of positional encoding (that allow us to retain higher frequency positional accuracy) results in
                    higher quality reconstruction, and more parameters allows us to put in more information in order to generalize our reconstruction.
                </p>
                <img src="images/part1/fish/feesh.jpg" alt="" width="500px"  loop=infinite />
                <figcaption>Two feesh! (sardeen)</figcaption>
                <br>
                <h4>
                    Baseline: 3000 Iterations, 10 Positional Encoding Levels, 256 Hidden Layers, 0.01 Learning Rate
                </h4>
                <div>
                    <table>
                        <tr>
                            <td>
                                <img src="images/part1/fish/3000i_1L_256h_001lr/Unknown.png" alt="" width="300px">
                            </td>
                            <td>
                                <img src="images/part1/fish/3000i_10L_256h_001lr/images/fish_100.jpeg" alt=""  width="300px">
                            </td>
                            <td>
                                <img src="images/part1/fish/3000i_10L_256h_001lr/fish_1.mov" alt=""  width="300px">
                            </td>
                            
                            
                        </tr>
                        <tr>
                            <td>
                                <figcaption>
                                    PSNR levels over 3000 iterations
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    Final reconstructed image
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    Image reconstruction while training
                                </figcaption>
                            </td>
                        </tr>
                        
                    </table>
                    <br>
                    <table>
                        <tr>
                            <td>
                                <img src="images/part1/fish/3000i_10L_256h_001lr/images/fish_1.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fish/3000i_10L_256h_001lr/images/fish_20.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fish/3000i_10L_256h_001lr/images/fish_40.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fish/3000i_10L_256h_001lr/images/fish_60.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fish/3000i_10L_256h_001lr/images/fish_100.jpeg" alt=""  width="200px">
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <figcaption>
                                    i=0
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=600
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=1200
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=1800
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=3000
                                </figcaption>
                            </td>
                        </tr>
                    </table>
                </div>
                <br>
                <h4>
                    3000 Iterations, <i>5 Positional Encoding Levels</i>, 256 Hidden Layers, 0.01 Learning Rate
                </h4>
                <div>
                    <table>
                        <tr>
                            <td>
                                <img src="images/part1/fish/3000i_5L_256h_001lr/Unknown.png" alt="" width="300px">
                            </td>
                            <td>
                                <img src="images/part1/fish/3000i_5L_256h_001lr/images2/fish_100.jpg" alt="" width="300px">
                            </td>
                            <td>
                                <img src="images/part1/fish/3000i_5L_256h_001lr/fish.mov" alt="" width="300px">
                            </td>
                        
                        </tr>
                        <td>
                            <figcaption>
                                PSNR levels over 3000 iterations
                            </figcaption>
                        </td>
                        <td>
                            <figcaption>
                                Final reconstructed image
                            </figcaption>
                        </td>
                        <td>
                            <figcaption>
                                Image reconstruction while training
                            </figcaption>
                        </td>
                    </table>
                    <br>
                    <table>
                        <tr>
                            <td>
                                <img src="images/part1/fish/3000i_5L_256h_001lr/images2/fish_1.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fish/3000i_5L_256h_001lr/images2/fish_20.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fish/3000i_5L_256h_001lr/images2/fish_40.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fish/3000i_5L_256h_001lr/images2/fish_60.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fish/3000i_5L_256h_001lr/images2/fish_100.jpg" alt=""  width="200px">
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <figcaption>
                                    i=0
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=600
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=1200
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=1800
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=3000
                                </figcaption>
                            </td>
                        </tr>
                    </table>
                </div>
                <br>
                <h4>
                    3000 Iterations, <i>1 Positional Encoding Level</i>, 256 Hidden Layers, 0.01 Learning Rate
                </h4>
                <div>
                    <table>
                        <tr>
                            <td>
                                <img src="images/part1/fish/3000i_1L_256h_001lr/Unknown.png" alt="" width="300px">
                            </td>
                            <td>
                                <img src="images/part1/fish/3000i_1L_256h_001lr/images1/fish_100.jpeg" alt="" width="300px">
                            </td>
                            <td>
                                <img src="images/part1/fish/3000i_1L_256h_001lr/fish.mov" alt="" width="300px">
                            </td>
                        
                        </tr>
                        
                        <td>
                            <figcaption>
                                PSNR levels over 3000 iterations
                            </figcaption>
                        </td>
                        <td>
                            <figcaption>
                                Final reconstructed image
                            </figcaption>
                        </td>
                        <td>
                            <figcaption>
                                Image reconstruction while training
                            </figcaption>
                        </td>
                        
                    </table>
                    <br>
                    <table>
                        <tr>
                            <td>
                                <img src="images/part1/fish/3000i_1L_256h_001lr/images1/fish_1.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fish/3000i_1L_256h_001lr/images1/fish_20.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fish/3000i_1L_256h_001lr/images1/fish_40.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fish/3000i_1L_256h_001lr/images1/fish_60.jpeg" alt=""  width="200px">
                            </td>
                            <td>
                                <img src="images/part1/fish/3000i_1L_256h_001lr/images1/fish_100.jpeg" alt=""  width="200px">
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <figcaption>
                                    i=0
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=600
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=1200
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=1800
                                </figcaption>
                            </td>
                            <td>
                                <figcaption>
                                    i=3000
                                </figcaption>
                            </td>
                        </tr>
                    </table>
                </div>
            </div>

        </div>
        <!-- End of part A -->

        <!-- Beginning of Part B -->
        <h2 align="middle">
            Part B: Fit a Neural Radiance Field from Multi-view Images
        </h2>
        
        <div align="middle">
            <h3>
                Create Rays from Cameras
            </h3>
            <div>
                <p>
                Now, we bring our ideas of image reconstruction to 3D in order to generate neural radiance fields. Firstly, we need
                to deal with image projections in 3D space, a.k.a., map world coordinates $(x_w, y_w, z_w)$ in 3D space to 2D pixel coordinates
                $(u,v)$ in image space. We create a matrix that converts an arbitrary world coordinate in 3D to a pixel coordinate on an image, 
                and its inverse to convert image coordinates into world coordinates:
                </p>
                \begin{equation}
                \begin{bmatrix} u \\ v \\ 1 \end{bmatrix} =  w2c * K^{-1} * \begin{bmatrix} x_w \\ y_w \\ z_w \end{bmatrix}
        
                \end{equation}
                <p>
                where $w2c$ is the world to camera transformation matrix and $K$ is the pixel to camera matrix.
                
                \begin{equation}
                K = \begin{bmatrix} f_x & 0 & o_x \\ 0 & f_y & o_y \\ 0 & 0 & 1 \end{bmatrix}
                \end{equation}
                \begin{equation}
                w2c = \begin{bmatrix} \mathbf{R}_{3\times3} &
                \mathbf{t} \\ \mathbf{0}_{1\times3} & 1 \end{bmatrix}  
                \end{equation}
                <p>
                    Furthermore, $w2c$ is the transformation matrix between homogeneous world and camera coordinates  $(x_w, y_w, z_w, 1)$
                    to $(x_c, y_c, z_c, 1)$ respectively, and in the equation above, we implicitly remove the extra dimension from the 
                    homogeneous camera coordinates before applying the camera to pixel transformation $K^{-1}$
                    deleted.

                </p>
                <p>
                    The other way around, from pixel coordinates to world coordinates, we can simply invert the matrices:
                </p>
                \begin{equation}
                \begin{bmatrix} x_w \\ y_w \\ z_w \end{bmatrix} = c2w * K * \begin{bmatrix} u \\ v \\ 1 \end{bmatrix}
                \end{equation}
                <p>
                    where
                </p>
                \begin{equation}
                c2w = \begin{bmatrix} \mathbf{R}_{3\times3} &
                \mathbf{t} \\ \mathbf{0}_{1\times3} & 1 \end{bmatrix}  ^{-1}
                \end{equation}

                <p>
                    In 3D world coordinates, a ray is specified by an origin, and a direction. 
                    Given an origin coordinate $r_o$ and another direction coordinate $r_d$, we can draw rays 
                    extending from our camera to our scene view. For a given camera, our $r_o$ and $r_d$ are calculated as:
                </p>

                    \begin{align} \mathbf{r}_o = -\mathbf{R}_{3\times3}^{-1}\mathbf{t} \end{align}
                    \begin{align} \mathbf{r}_d = \frac{\mathbf{X_w} - \mathbf{r}_o}{||\mathbf{X_w} - \mathbf{r}_o||_2} \end{align}
                <p>
                    Together, we can calculate a ray from pure image coordinates by placing the origin ray 1 unit away from the 
                    image plane, so that the world coordinate of the image pixel represents the direction of the ray. 
                </p>
            </div>
            <h3>Sampling</h3>
            <div>
                <p>
                    Once we have our rays, we would like to sample along the ray so that we can calculate the
                    color and density of a 3D volumetric representation. The volume rendering equation is:
                </p>
                \begin{align} C(\mathbf{r})=\int_{t_n}^{t_f} T(t) \sigma(\mathbf{r}(t))
      \mathbf{c}(\mathbf{r}(t), \mathbf{d}) d t, \text { where } T(t)=\exp \left(-\int_{t_n}^t \sigma(\mathbf{r}(s)) d s\right)
      \end{align}
                <p>
                    Because it is computationally intractable to to get the color at every infinitesimal $dt$ 
                    along the ray $\textbf{r}(t)$ with this integral, we discretely approximate it to:
                </p>
                \begin{align}
                \hat{C}(\mathbf{r})=\sum_{i=1}^N T_i\left(1-\exp \left(-\sigma_i \delta_i\right)\right) \mathbf{c}_i, \text { where } T_i=\exp
                \left(-\sum_{j=1}^{i-1} \sigma_j \delta_j\right) \end{align}
                <p>
                    Thus, we sample along the ray with a near clipping plane of 2 and a far clipping plane of 4. We attempt to get a 
                    uniformly random distributed set of sample points along the ray, by first getting 64 samples with a step size of (6 - 4) / 64
                    then perturbing each sample along the ray uniformly within 0.02 units in order to avoid overfitting when training.
                </p>
            </div>
            <h3>Putting the Dataloading All Together</h3>
            <div>
                <p>
                    We created a dataloader that generates 10000 random rays when you initialize it with a set of images. Here, we 
                    randomly sample N rays extending from a randomly sampled M images, with 64 samples along each ray, rendered in 
                    <a href="https://github.com/nerfstudio-project/viser">Viser</a>:
                </p>
                <img src="images/part2/cam.png" alt="" width="500px">
                
            </div>
            <h3>Neural Radiance Fields</h3>
            <div>
                <p>
                    Similar to part 1, we would like to take as input a 3D coordinate and output a predicted color in rgb and its density at that point.
                    We create a neural network, inputting in a 3D coordinate and positionally encoding it. At some intermediary step, 
                    we also posiitonally encode the ray direction and insert it into our model. Here is the architecture:
                </p>
                <img src="images/part2/mlp_nerf.png" alt=""width="700px">
                
                <p>
                    Initially, we trained on 1000 iterations with a learning rate of 0.0005 on an Adam optimizer, with a MSE loss
                    comparing the pixel values of our predicted image view with the original image input, and 10 positional encoding levels. 
                    There are 64 samples along each ray for volumetric rendering.
                    
                </p>
                <p>
                    For ray sampling, we randomly sampled, with replacement, 10 images at a time, with 10000 rays in a batch. We uniformly
                    sampled pixels over all 10 images at a time (i.e. 1000 rays per image). However, the resulting PSNR levels were relatively low, 
                    so we decided to sample over all 100 images at once (i.e. 100 rays per image). Our PSNR levels went up, but still lower than staff's.

                </p>
                <p>
                    Eventually, we decided to use a learning rate of 0.001, which, for 1000 iterations, improved the PSNR ~3 levels more.
                    We reached a final PSNR level of 23.856! Better than staff solution.
                </p>

                <p>
                    Furthermore, we managed to cut down our training time from 1 hour to 10 minutes. Here are some things we optimized on:
                    <ul align="left">
                        <li>
                            We computed rays in batches on the GPU with torch tensors
                        </li>
                        <li>
                            For each camera, we computed the origin rays for each camera upon initialization of the data manager. During sampling,
                            we would generate an array of indices and query the cameras with thier corresponding origin rays while sampling pixels
                        </li>
                    </ul>
                </p>
                <h4>
                    1000 Iterations, 10000 Batchsize, 10 Positional Encoding Levels, 64 Samples per ray, 256 Hidden Layers, 0.001 Learning Rate
                </h4>
                <table>
                    <tr>
                        <td>
                            <img src="images/part2/Unknown.png" alt="" width="300px">
                        </td>
                        <td>
                            <img src="images/part2/training/Unknown-5.png" alt="" width="300px">
                        </td>
                        <td>
                            <img src="images/part2/nerf.gif" alt="" width="300px">
                        </td>
                        
                    </tr>
                    <tr>
                        <td>
                            <figcaption>
                                PSNR levels over 1000 iterations
                            </figcaption>
                        </td>
                        <td>
                            <figcaption>
                                final render after training
                            </figcaption>
                        </td>
                        <td>
                            <figcaption>
                                60 novel camera views (refresh page if stuck)
                            </figcaption>
                        </td>
                    </tr>
                    
                </table>

                <h4>
                    Training iteration level (i) along with predicted image
                </h4>
                <table>
                    <tr>
                        <td>
                            <img src="images/part2/training/Unknown.png" alt=""  width="200px">
                        </td>
                        <td>
                            <img src="images/part2/training/Unknown-1.png" alt=""  width="200px">
                        </td>
                        <td>
                            <img src="images/part2/training/Unknown-2.png" alt=""  width="200px">
                        </td>
                        <td>
                            <img src="images/part2/training/Unknown-3.png" alt=""  width="200px">
                        </td>
                        <td>
                            <img src="images/part2/training/Unknown-5.png" alt=""  width="200px">
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <figcaption>
                                i=1
                            </figcaption>
                        </td>
                        <td>
                            <figcaption>
                                i=200
                            </figcaption>
                        </td>
                        <td>
                            <figcaption>
                                i=400
                            </figcaption>
                        </td>
                        <td>
                            <figcaption>
                                i=600
                            </figcaption>
                        </td>
                        <td>
                            <figcaption>
                                i=1000
                            </figcaption>
                        </td>
                    </tr>
                </table>
            </div>
        </div>
        <!-- End of part B -->

        <!-- Beginning of Bells and Whistles -->
        <h2>
            Bells and Whistles
        </h2>
        <div align="middle">
            <p>
                Here's an Autodesk Maya plugin that Rebecca made for Nerfstudio. Essentially, it computes the corresponding 
                camera extrinsics and intrinsics with respect to the mesh representation of the NeRF in Maya for every animation
                frame, and writes a camera path json file that can be opened and processed in Nerfstudio to render scenes, 
                allowing the user to combine animations in Nerfstudio and in Maya! Here is a small animation combined with Cyrus Vachha's
                Doe Platform Sundown dataset. Taking a character asset from the 3D Modeling and Animation at Berkeley club ( 
                which Rebecca sculpted), she composited the rendered animation with the nerf scene using the plugin. Still have to reformat some
                code but here's the <a href="https://github.com/nerfstudio-project/nerfstudio/pull/3519">pull request</a> and 
                <a href="../../nerfstudio/nerfplugin_maya.py" download>link to download</a>
               

            </p>
            <iframe width="560" height="315" src="https://www.youtube.com/embed/cMKkKLZ3Akg?si=eGWoxKqxacrYLgUO" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
    </body>
</html>